{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bfdae7-43b6-476d-b543-87fa75a1bc46",
   "metadata": {},
   "source": [
    "1. run in shell: `python create_env.py`\n",
    "    * dependencies: `install_pkgs.py`, `requirements-aws.txt`, `requirements.txt`\n",
    "    * output: `rearc_project`\n",
    "2. run in shell: `source create_kernel.zsh`\n",
    "    * dependencies: `jupyter-lab`\n",
    "3. select kernel: `rearc_project`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05d89629-8c83-409c-af1c-a9a35f8197b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import hashlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714db35d-676b-4139-8d6f-a4b8bd944fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aws_cdk import core\n",
    "from aws_cdk import aws_lambda as _lambda\n",
    "from aws_cdk import aws_sqs as sqs\n",
    "from aws_cdk import aws_s3 as s3\n",
    "from aws_cdk import aws_events as events\n",
    "from aws_cdk import aws_events_targets as targets\n",
    "from aws_cdk import aws_iam as iam\n",
    "from aws_cdk import aws_s3_notifications\n",
    "from aws_cdk.aws_s3_notifications import SqsDestination\n",
    "\n",
    "##-- Initialize Spark session - OPTIONAL\n",
    "# os.environ['PYARROW_IGNORE_TIMEZONE'] = '1'\n",
    "# from pyspark.sql import SparkSession\n",
    "# import pyspark.pandas as ps\n",
    "# from pyspark.sql import functions as F\n",
    "# from pyspark.sql.window import Window\n",
    "# spark = SparkSession.builder.appName(\"LoadData\").getOrCreate()        \n",
    "# spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f91017-4d9c-47bf-8b45-fae74ff0e4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##------------------------------------------##\n",
    "##-- Load AWS Configurations\n",
    "##------------------------------------------##\n",
    "info = (lambda f: json.load(f))(open(\"info.txt\", 'r'))\n",
    "    \n",
    "AWS_ACCESS_KEY = info[\"secrets\"][\"AWS_ACCESS_KEY\"]\n",
    "AWS_SECRET_ACCESS = info[\"secrets\"][\"AWS_SECRET_ACCESS\"]\n",
    "AWS_ARN = info[\"secrets\"][\"AWS_ARN\"]\n",
    "AWS_REGION = info[\"secrets\"][\"AWS_REGION\"]\n",
    "\n",
    "S3_BUCKET = info['pipeline'][\"S3_BUCKET\"]\n",
    "SQS_QUEUE = info['pipeline'][\"SQS_QUEUE\"] \n",
    "LAMBDA_P1_P2 = info['pipeline'][\"LAMBDA_P1_P2\"]\n",
    "LAMBDA_P3 = info['pipeline'][\"LAMBDA_P3\"]\n",
    "\n",
    "##------------------------------------------##\n",
    "##-- Initialize AWS Clients\n",
    "##------------------------------------------##\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "lambda_client = boto3.client(\n",
    "    'lambda',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "\n",
    "sqs_client = boto3.client(\n",
    "    'sqs',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS,\n",
    "    region_name=AWS_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b910766-425e-4e6c-a1ab-9136a34d68e4",
   "metadata": {},
   "source": [
    "### Part 1: AWS S3 & Sourcing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1582253-f854-45da-bdf3-5aaafbaf1f39",
   "metadata": {},
   "source": [
    "1. Republish this open dataset (https://download.bls.gov/pub/time.series/pr) in Amazon S3 and share with us a link.\n",
    "    * You may run into 403 Forbidden errors as you test accessing this data. There is a way to comply with the BLS data access policies and regain access to fetch this data programmatically - we have included some hints as to how to do this at the bottom of this README in the Q/A section.\n",
    "2. Script this process so the files in the S3 bucket are kept in sync with the source when data on the website is updated, added, or deleted.\n",
    "    * Don't rely on hard-coded names - the script should be able to handle added or removed files.\n",
    "    * Ensure the script doesn't upload the same file more than once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ce5b36-8b82-417f-b1a0-dd2a734e8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd77d01-c6a1-447c-8b96-795135b994ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File pr.class already exists in s3://bls-data-sample-rearc/\n",
      "File pr.contacts already exists in s3://bls-data-sample-rearc/\n",
      "File pr.data.0.Current already exists in s3://bls-data-sample-rearc/\n",
      "File pr.data.1.AllData already exists in s3://bls-data-sample-rearc/\n",
      "File pr.duration already exists in s3://bls-data-sample-rearc/\n",
      "File pr.footnote already exists in s3://bls-data-sample-rearc/\n",
      "File pr.measure already exists in s3://bls-data-sample-rearc/\n",
      "File pr.period already exists in s3://bls-data-sample-rearc/\n",
      "File pr.seasonal already exists in s3://bls-data-sample-rearc/\n",
      "File pr.sector already exists in s3://bls-data-sample-rearc/\n",
      "File pr.series already exists in s3://bls-data-sample-rearc/\n",
      "File pr.txt already exists in s3://bls-data-sample-rearc/\n"
     ]
    }
   ],
   "source": [
    "##-- Function to download and upload files\n",
    "def fetch_and_upload(file_name):\n",
    "    file_url = urljoin(base_url, file_name)\n",
    "    r = requests.get(file_url, headers={'User-Agent': 'test'})\n",
    "    local_file = f\"/tmp/{file_name}\"\n",
    "\n",
    "    with open(local_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    current_md5 = md5(local_file)\n",
    "    \n",
    "    try:\n",
    "        s3_md5 = s3_client.head_object(Bucket=S3_BUCKET, Key=file_name)['ETag'][1:-1]\n",
    "        \n",
    "        if current_md5 != s3_md5:\n",
    "            s3_client.upload_file(local_file, S3_BUCKET, file_name)\n",
    "            print(f\"Uploaded {file_name} to s3://{S3_BUCKET}/\")\n",
    "        else:\n",
    "            # print(f\"File {file_name} already exists\")\n",
    "            print(f\"File {file_name} already exists in s3://{S3_BUCKET}/\")\n",
    "\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] in ('403', '404'):\n",
    "            s3_client.upload_file(local_file, S3_BUCKET, file_name)\n",
    "            print(f\"Uploaded {file_name} to s3://{S3_BUCKET}/\")\n",
    "\n",
    "    os.remove(local_file)\n",
    "\n",
    "##-- Fetch the webpage with file links\n",
    "base_url = \"https://download.bls.gov/pub/time.series/pr/\"\n",
    "r = requests.get(base_url, headers={'User-Agent': 'test'})\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "##-- Loop through and download/upload each file\n",
    "for link in soup.find_all('a'):\n",
    "    file_name = os.path.basename(urlparse(link.get('href')).path)\n",
    "    if file_name:\n",
    "        # print(file_name)\n",
    "        fetch_and_upload(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff14e47-12e2-44cb-a778-fc22da5ceea2",
   "metadata": {},
   "source": [
    "### Part 2: APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544b9c2-a09a-437b-88fa-65488980a5ed",
   "metadata": {},
   "source": [
    "1. Create a script that will fetch data from this API (https://datausa.io/api/data?drilldowns=Nation&measures=Population). You can read the documentation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "465311a0-951d-4504-bbcc-419b96d3163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Fetch data from API\n",
    "api_url = \"https://datausa.io/api/data?drilldowns=Nation&measures=Population\"\n",
    "response = requests.get(api_url)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb3d20b-1fd9-4b75-889a-20230c2f4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Save to temporary JSON file\n",
    "with open(\"/tmp/population_data.json\", \"w\") as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce8476-7606-4d5e-809e-6e3d8f891a73",
   "metadata": {},
   "source": [
    "2. Save the result of this API call as a JSON file in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f0a1a2-9197-42da-b8fc-5f9ca94402c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to s3://bls-data-sample-rearc/population_data.json\n"
     ]
    }
   ],
   "source": [
    "##-- Upload to S3\n",
    "s3_client.upload_file(\"/tmp/population_data.json\", S3_BUCKET, \"population_data.json\")\n",
    "print(f\"Data uploaded to s3://{S3_BUCKET}/population_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50f4aa-cffe-4a8a-ac5a-b1c5548dc87d",
   "metadata": {},
   "source": [
    "### Part 3: Data Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16537ffe-c631-4263-b523-29341c7fda83",
   "metadata": {},
   "source": [
    "0. Load both the CSV file from Part 1 pr.data.0.Current and the JSON file from Part 2 as dataframes (Spark, Pyspark, Pandas, Koalas, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b340d4-867a-48ef-83ff-1039b56c3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Download file from S3 to local\n",
    "s3_client.download_file(f'{S3_BUCKET}', 'population_data.json', 'population_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61f2095-93d6-45fd-81a4-bf7515b9ce79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nation</th>\n",
       "      <th>id_year</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>slug_nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>326569308</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>324697795</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>322903030</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>321004407</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>318558162</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         nation  id_year  year  population    slug_nation\n",
       "0  01000US  United States     2020  2020   326569308  united-states\n",
       "1  01000US  United States     2019  2019   324697795  united-states\n",
       "2  01000US  United States     2018  2018   322903030  united-states\n",
       "3  01000US  United States     2017  2017   321004407  united-states\n",
       "4  01000US  United States     2016  2016   318558162  united-states"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- Load JSON file and flatten\n",
    "read_json = lambda filename: json.load(open(filename, 'r'))\n",
    "json_obj = read_json('population_data.json')\n",
    "flattened_data = json_obj['data']\n",
    "data_types_p2 = {'id':'str', 'nation':'str', 'slug_nation':'str', 'id_year':'int','year':'int', 'population':'int'}\n",
    "col_mapping_p2 = {'ID Nation':'id', 'Nation':'nation', 'Slug Nation':'slug_nation','ID Year':'id_year', 'Year':'year', 'Population':'population'}\n",
    "df_p2 = pd.DataFrame(flattened_data)\n",
    "df_p2.rename(columns=col_mapping_p2, inplace=True)\n",
    "df_p2 = df_p2.astype(data_types_p2)\n",
    "df_p2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902e893-27f5-4349-9eda-678dd0f16b07",
   "metadata": {},
   "source": [
    "1. Using the dataframe from the population data API (Part 2), generate the mean and the standard deviation of the annual US population across the years [2013, 2018] inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59348d81-cdff-4411-867b-52e0c974ea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Population: 317437383.00\n",
      "Standard Deviation: 4257089.54\n"
     ]
    }
   ],
   "source": [
    "##-- Filter DataFrame: 2013-2018\n",
    "filtered_df = df_p2[df_p2['year'].isin([year for year in range(2013, 2019)])]\n",
    "\n",
    "##-- Calculate mean & standard deviation\n",
    "mean_pop = filtered_df['population'].mean()\n",
    "std_pop = filtered_df['population'].std()\n",
    "\n",
    "print(f\"Mean Population: {mean_pop:.2f}\")\n",
    "print(f\"Standard Deviation: {std_pop:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbd07d-5969-4a49-836b-3530053da9bd",
   "metadata": {},
   "source": [
    "2. Using the dataframe from the time series (Part 1), for every series_id, find the best year: the year with the max/largest sum of \"value\" for all quarters in that year. Generate a report with each series id, the best year for that series, and the summed value for that year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939586d8-e9f1-4617-8b26-be1609c67380",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- Download file from S3 to local\n",
    "s3_client.download_file(f'{S3_BUCKET}', 'pr.data.0.Current', 'current_localfile.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0189608-28ec-4c24-8e34-3856af35ce8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>footnote_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q02</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q03</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q05</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     series_id  year period  value footnote_codes\n",
       "0  PRS30006011  1995    Q01    2.6            NaN\n",
       "1  PRS30006011  1995    Q02    2.1            NaN\n",
       "2  PRS30006011  1995    Q03    0.9            NaN\n",
       "3  PRS30006011  1995    Q04    0.1            NaN\n",
       "4  PRS30006011  1995    Q05    1.4            NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- Load CSV file \n",
    "data_types_p1 = {'series_id':'str', 'year':'int', 'period':'str', 'value':'float', 'footnote_codes':'str'}\n",
    "df_p1 = pd.read_csv('current_localfile.txt', sep=\"\\t\", dtype=data_types_p1)\n",
    "df_p1.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "df_p1 = df_p1.map(lambda x: x.replace(' ', '') if isinstance(x, str) else x)\n",
    "df_p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "606aeb67-4176-4ce4-8ad5-da6a937c7a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>-127.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006012</td>\n",
       "      <td>-124.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006013</td>\n",
       "      <td>16590.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006021</td>\n",
       "      <td>-6.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006022</td>\n",
       "      <td>-5.400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     series_id      value\n",
       "0  PRS30006011   -127.000\n",
       "1  PRS30006012   -124.300\n",
       "2  PRS30006013  16590.938\n",
       "3  PRS30006021     -6.300\n",
       "4  PRS30006022     -5.400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- Group by 'series_id', sum the 'value' and find the max\n",
    "grouped_df = df_p1.groupby('series_id')['value'].sum().reset_index()\n",
    "max_value_row = grouped_df[grouped_df['value'] == grouped_df['value'].max()]\n",
    "grouped_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf55da6-3109-489f-b37b-b0df11ad6f40",
   "metadata": {},
   "source": [
    "3. Generate a report that will provide the value for series_id = PRS30006032 and period = Q01 and the population for that given year (if available in the population dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83cc0e30-8f77-4f92-9902-bd4a1a06c168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>footnote_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1996</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1997</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1998</td>\n",
       "      <td>Q01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1999</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        series_id  year period  value footnote_codes\n",
       "994   PRS30006032  1995    Q01    0.0            NaN\n",
       "999   PRS30006032  1996    Q01   -4.4            NaN\n",
       "1004  PRS30006032  1997    Q01    2.7            NaN\n",
       "1009  PRS30006032  1998    Q01    1.0            NaN\n",
       "1014  PRS30006032  1999    Q01   -4.1            NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- filter dataframe 1\n",
    "filtered_df_p1 = df_p1[(df_p1['series_id'] == 'PRS30006032') & (df_p1['period'] == 'Q01')]\n",
    "filtered_df_p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "846a199d-f168-42c4-949f-2f8f0acc43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nation</th>\n",
       "      <th>id_year</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>slug_nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>326569308</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>324697795</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>322903030</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017</td>\n",
       "      <td>321004407</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01000US</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>318558162</td>\n",
       "      <td>united-states</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         nation  id_year  year  population    slug_nation\n",
       "0  01000US  United States     2020  2020   326569308  united-states\n",
       "1  01000US  United States     2019  2019   324697795  united-states\n",
       "2  01000US  United States     2018  2018   322903030  united-states\n",
       "3  01000US  United States     2017  2017   321004407  united-states\n",
       "4  01000US  United States     2016  2016   318558162  united-states"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##-- filter dataframe 2\n",
    "filtered_df_p2 = df_p2[ df_p2['year'].isin(filtered_df_p1['year']) ]\n",
    "filtered_df_p2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f125ba-c806-49b7-84a1-0f3addb470aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1996</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1997</td>\n",
       "      <td>2.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1999</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2001</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2002</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2003</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2004</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2005</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2006</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2007</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2008</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2009</td>\n",
       "      <td>-20.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.2</td>\n",
       "      <td>311536594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314107084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2015</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>316515021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2016</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>318558162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321004407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>322903030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2019</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>324697795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2020</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>326569308.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2021</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      series_id  year  value   population\n",
       "0   PRS30006032  1995    0.0          NaN\n",
       "1   PRS30006032  1996   -4.4          NaN\n",
       "2   PRS30006032  1997    2.7          NaN\n",
       "3   PRS30006032  1998    1.0          NaN\n",
       "4   PRS30006032  1999   -4.1          NaN\n",
       "5   PRS30006032  2000    0.1          NaN\n",
       "6   PRS30006032  2001   -6.0          NaN\n",
       "7   PRS30006032  2002   -7.0          NaN\n",
       "8   PRS30006032  2003   -5.7          NaN\n",
       "9   PRS30006032  2004    2.4          NaN\n",
       "10  PRS30006032  2005   -1.1          NaN\n",
       "11  PRS30006032  2006    2.8          NaN\n",
       "12  PRS30006032  2007   -0.3          NaN\n",
       "13  PRS30006032  2008   -3.4          NaN\n",
       "14  PRS30006032  2009  -20.7          NaN\n",
       "15  PRS30006032  2010    3.5          NaN\n",
       "16  PRS30006032  2011    1.6          NaN\n",
       "17  PRS30006032  2012    3.0          NaN\n",
       "18  PRS30006032  2013    1.2  311536594.0\n",
       "19  PRS30006032  2014    0.0  314107084.0\n",
       "20  PRS30006032  2015   -1.7  316515021.0\n",
       "21  PRS30006032  2016   -1.8  318558162.0\n",
       "22  PRS30006032  2017    1.0  321004407.0\n",
       "23  PRS30006032  2018   -0.1  322903030.0\n",
       "24  PRS30006032  2019   -2.4  324697795.0\n",
       "25  PRS30006032  2020   -6.5  326569308.0\n",
       "26  PRS30006032  2021    1.3          NaN\n",
       "27  PRS30006032  2022    7.3          NaN\n",
       "28  PRS30006032  2023    1.5          NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##-- Merge dataframes 1 & 2\n",
    "result = pd.merge(filtered_df_p1, filtered_df_p2, left_on='year', right_on='year', how='left')\n",
    "report_df = result[['series_id', 'year', 'value', 'population']]\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cea8caa-a366-418f-aa41-cc98fa935c18",
   "metadata": {},
   "source": [
    "### Part 4: Infrastructure as Code & Data Pipeline with AWS CDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a2a6c-3113-4e1f-b2f5-7868e57ee0cb",
   "metadata": {},
   "source": [
    "1. run in shell: `python create_env.py`\n",
    "    * dependencies: `install_pkgs.py`, `requirements-aws.txt`, `requirements.txt`\n",
    "    * output: `rearc_project`\n",
    "2. run in shell: `source create_kernel.zsh`\n",
    "    * dependencies: `jupyter-lab`\n",
    "3. run in shell: `python main.py`\n",
    "    * dependencies: \n",
    "        * `info.txt`\n",
    "        * `bls-lambda-p1-p2-sample-rearc.py`\n",
    "        * `bls-lambda-p1-p2-sample-rearc.zip`\n",
    "        * `bls-lambda-p3-sample-rearc.py`\n",
    "        * `bls-lambda-p3-sample-rearc.zip`\n",
    "    * output: \n",
    "        * `population_data.json`\n",
    "        * `current_localfile.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d844e-570c-49ac-873c-a16bdda87409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rearc_project",
   "language": "python",
   "name": "rearc_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
